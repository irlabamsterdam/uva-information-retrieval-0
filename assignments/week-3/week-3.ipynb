{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6690dfe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Before you turn this assignment in, make sure everything runs as expected by going to the menubar and running: \n",
    "\n",
    "**Kernel $\\rightarrow$ Restart & Run All**\n",
    "\n",
    "Please replace all spots marked with `# ADD YOUR CODE HERE` or `ADD YOUR ANSWER HERE`.\n",
    "\n",
    "And start by filling in your name and student_id below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef5aec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "STUDENT_ID = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d57790",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert len(NAME) > 0, \"Please fill in your name\"\n",
    "assert len(STUDENT_ID) > 0, \"Please fill in your student id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501329c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa61b4e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:30.122568Z",
     "start_time": "2024-08-27T13:20:30.116455Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1a432391d0326c97360a3c247c757da",
     "grade": false,
     "grade_id": "cell-186e1e44f0bd2d60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import doctest\n",
    "import string\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from math import log\n",
    "from typing import Callable, List, Dict, Tuple\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nltk.download(\"punkt_tab\");\n",
    "    nltk.download(\"stopwords\");\n",
    "\n",
    "    # Enable doctests\n",
    "    def test(fn: Callable):\n",
    "        doctest.run_docstring_examples(fn, globals(), verbose=True, name=fn.__name__)\n",
    "else:\n",
    "    # Disable doctests in autograding setup\n",
    "    def test(fn: Callable): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2890506",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e598fe979938bcc250a64a8343c98eb5",
     "grade": false,
     "grade_id": "cell-b4d821343ae97089",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Week 3 - Preprocessing & Vector Space Model\n",
    "\n",
    "Welcome to week three of the search engines course üëã\n",
    "\n",
    "Part I of this week takes a look at preprocessing documents for retrieval. In part II, we will build our first ranked search engine using tf-idf scoring. And in part III, we will build a language-model-based search engine.\n",
    "\n",
    "As always, for any questions, problems, or feedback please contact your TA. Good luck with the assignment!\n",
    "\n",
    "### Resources\n",
    "\n",
    "üìö [Preprocessing - Manning, Raghavan, Sch√ºtze - Chapter 2.2](https://nlp.stanford.edu/IR-book/pdf/02voc.pdf)\n",
    "\n",
    "üìö [Vector Space Model - Manning, Raghavan, Sch√ºtze - Chapter 6.3](https://nlp.stanford.edu/IR-book/pdf/06vect.pdf)\n",
    "\n",
    "üìö [Preprocessing - Croft, Metzler, and Strohman - Chapter 4.3](https://ciir.cs.umass.edu/downloads/SEIRiP.pdf#page=110)\n",
    "\n",
    "üìö [Vector Space Model - Croft, Metzler, and Strohman - Chapter 7.1.2](https://ciir.cs.umass.edu/downloads/SEIRiP.pdf#page=261)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb17aec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e52ed21299de0c9274aab8c0893d9ec9",
     "grade": false,
     "grade_id": "cell-6d3870748e75a948",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part I - Preprocessing\n",
    "\n",
    "The Netflix dataset that we used in the first week was already preprocessed. Since you learned more about the different steps of preprocessing documents in this week's lecture, let's take a closer look at preprocessing documents for IR. For this, we will use a subset of a real dataset from a public TREC challenge for [biomedical information retrieval about Covid-19](https://ir.nist.gov/trec-covid/). We will process medical abstracts concerning vitamins in connection with covid. To make things a bit more interesting, we added a very simple boolean search engine below, which we will use to evaluate each step of our preprocessing pipeline.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "‚ö†Ô∏è Note: To be very clear, this is not an endorsement of treating covid-19 with vitamins. For more info see: https://www.mayoclinic.org/diseases-conditions/coronavirus/expert-answers/coronavirus-and-vitamin-d/faq-20493088\n",
    "</div>\n",
    "    \n",
    "Let's begin by executing the boilerplate code below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97f4dd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2a5a2dc62721372eaafce4bce663946",
     "grade": false,
     "grade_id": "cell-9c4bf45c5b72e4ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Setup I: Simple boolean search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe522dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:30.424548Z",
     "start_time": "2024-08-27T13:20:30.309114Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18e54d818c45c7b66014b144bfd41fd4",
     "grade": false,
     "grade_id": "cell-9c91f773f5be078a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_covid_data(\n",
    "    url: str = \"https://raw.githubusercontent.com/irlabamsterdam/uva-ir0-assignments/main/data/trec-covid.csv\"\n",
    "):\n",
    "    return pd.read_csv(url)\n",
    "\n",
    "def create_index(df):\n",
    "    index = defaultdict(list)\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        tokens = preprocessing(row.text)\n",
    "\n",
    "        for token in tokens:\n",
    "            index[token].append(row.doc_id)\n",
    "\n",
    "    return index\n",
    "\n",
    "def search_and(index, query):\n",
    "    tokens = preprocessing(query)\n",
    "    return set.intersection(*[set(index[token]) for token in tokens])\n",
    "\n",
    "def precision(scores):\n",
    "    return sum(scores) / len(scores) if len(scores) > 0 else 0\n",
    "\n",
    "def recall(scores, max_scores):\n",
    "    return sum(scores) / sum(max_scores)\n",
    "\n",
    "def f1(scores, max_scores):\n",
    "    p = precision(scores)\n",
    "    r = recall(scores, max_scores)\n",
    "    return (2 * p * r) / (p + r) if (p + r) > 0 else 0\n",
    "\n",
    "def evaluate(df):\n",
    "    # Disable execution in autograde \n",
    "    if __name__ != \"__main__\": return\n",
    "\n",
    "    index = create_index(df)\n",
    "    index_size = len(index)\n",
    "    doc2relevance = df.set_index(\"doc_id\").relevance.to_dict()\n",
    "    max_scores = list(df.doc_id.map(doc2relevance))\n",
    "\n",
    "    queries = [\n",
    "        (\"A\", \"Vitamin D and COVID-19\"),\n",
    "        (\"B\", \"which vitamins against Sars-Cov-2?\"),\n",
    "        (\"C\", \"Vitamin A or D for the coronavirus?\")\n",
    "    ]\n",
    "\n",
    "    print(f\"Inverted index size: {index_size} tokens\\n\")\n",
    "\n",
    "    for query_id, query in queries:\n",
    "        docs = search_and(index, query)\n",
    "        scores = [doc2relevance[d] for d in docs]\n",
    "\n",
    "        print(f\"Query {query_id}: '{query}' -> {preprocessing(query)}\")\n",
    "        print(\n",
    "            f\"Precision: {precision(scores):.4f},\",\n",
    "            f\"Recall: {recall(scores, max_scores):.4f},\",\n",
    "            f\"F1: {f1(scores, max_scores):.4f},\",\n",
    "            f\"Retrieved docs: {len(docs)}/{len(max_scores)}\\n\",\n",
    "        )\n",
    "\n",
    "\n",
    "df = load_covid_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ddc2c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34785a0b71d4ac02553ea84bb7143a04",
     "grade": false,
     "grade_id": "cell-b844f9206f0e2a5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Setup II: Preprocessing pipeline\n",
    "\n",
    "Below is an (empty) preprocessing pipeline. In the following, we will overwrite each step with the actual preprocessing code. When calling `evaluate(df)`, we build a new index with our updated pipeline and evaluate the impact of our preprocessing on three queries (A, B, C) all roughly expressing a similar information need from the TRECT corpus: \"Do vitamins help against Covid-19?\".\n",
    "\n",
    "#### Test Queries\n",
    "* **A:** Vitamin D and COVID-19\n",
    "* **B:** Which vitamins against Sars-Cov-2?\n",
    "* **C:** Vitamin A or D for the coronavirus?\n",
    "\n",
    "After running the code below, you should be able to see the evaluation output for each of the three queries. For simplicity, we evaluate the ranking with the set-based metrics introduced last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc48e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:31.006892Z",
     "start_time": "2024-08-27T13:20:30.580619Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1801930086dfa440d8ec8682120802c",
     "grade": false,
     "grade_id": "cell-d9599ee2d8967edc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(text: str):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = normalize(tokens)\n",
    "    tokens = stopping(tokens)\n",
    "    tokens = stemming(tokens)\n",
    "    return tokens\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return text.split()\n",
    "\n",
    "def normalize(tokens: List[str]) -> List[str]:\n",
    "    return tokens\n",
    "\n",
    "def stopping(tokens: List[str]) -> List[str]:\n",
    "    return tokens\n",
    "\n",
    "def stemming(tokens: List[str]) -> List[str]:\n",
    "    return tokens\n",
    "\n",
    "\n",
    "evaluate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4793b90",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55edc49c4b08d74f9810cac25dd6aae0",
     "grade": false,
     "grade_id": "cell-fd18d3121cb83ae5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1 Tokenization\n",
    "\n",
    "After executing all this boilerplate, it is your turn! The first important step in our pipeline is tokenization, the process of splitting a piece of text into individual tokens. Tokenization is a complex and critical process. We might think that we have to break text on punctuation and spaces. However, we would rarely want to break tokens like `Ph.D.` or `U.K.` apart, while splitting certain pre- or suffixes is sometimes desirable. To make matters worse, tokenization is heavily language-dependent. If you are curious, take a look at an industry-grade rule-based [tokenizer from the spaCy library](https://spacy.io/usage/linguistic-features#tokenization). Modern LLMs train specific models that learn how to tokenize a piece of text (typically using statistics of co-occurring characters). But for this course, we will stick to a more classic rule-based approach.\n",
    "\n",
    "\n",
    "üìù Replace the following naive tokenization on whitespace with a more sophisticated tokenizer:\n",
    "\n",
    "1. Replace line breaks (`\\n`) with spaces.\n",
    "2. Replace the following special characters with spaces: `({[])}`\n",
    "3. Remove all of the following punctuation if followed by more punctuation, whitespace, or is at the end of the text: `.,!?;:`\n",
    "4. Split contractions such as `\"don't\" -> [\"do\", \"n't\"]` into separate tokens, use the list of contractions below.\n",
    "5. Lastly, break all tokens on whitespace and return a list of all tokens.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "üí° Regular expressions such as `re.replace(pattern, replacement, text)` might come in handy but are not necessary to solve this task!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ffc19-2b5c-428b-a456-9fec15fb232c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:31.096197Z",
     "start_time": "2024-08-27T13:20:31.092955Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ad18f441d2ad7b61bac65a48503b2ba",
     "grade": false,
     "grade_id": "cell-f40ef9cbb8b53de4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "contractions = [\"'m\", \"'s\", \"'d\", \"'ll\", \"'ve\", \"'re\", \"n't\"]\n",
    "\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    >>> tokenize(\"I'm, she's, we'd, he'll, we've, they're, ain't, don't, hadn't, isn't, shan't, might've\")\n",
    "    ['I', \"'m\", 'she', \"'s\", 'we', \"'d\", 'he', \"'ll\", 'we', \"'ve\", 'they', \"'re\", 'ai', \"n't\", 'do', \"n't\", 'had', \"n't\", 'is', \"n't\", 'sha', \"n't\", 'might', \"'ve\"]\n",
    "    \n",
    "    >>> tokenize(\"She said, `HELLO!` Then she paused.\\\\nDid you hear that? I wonder, should we go now?\")\n",
    "    ['She', 'said', '`HELLO!`', 'Then', 'she', 'paused', 'Did', 'you', 'hear', 'that', 'I', 'wonder', 'should', 'we', 'go', 'now']\n",
    "    \n",
    "    >>> tokenize(\"The committee's decision (which wasn't unanimous‚Äîthere were several objections [notably from Smith, Ph.D. and Prof. Johnson]) was announced at 3:00 p.m.; however, the report won't be released until tomorrow.\")\n",
    "    ['The', 'committee', \"'s\", 'decision', 'which', 'was', \"n't\", 'unanimous‚Äîthere', 'were', 'several', 'objections', 'notably', 'from', 'Smith', 'Ph.D', 'and', 'Prof', 'Johnson', 'was', 'announced', 'at', '3:00', 'p.m', 'however', 'the', 'report', 'wo', \"n't\", 'be', 'released', 'until', 'tomorrow']\n",
    "    \n",
    "    >>> tokenize(\" This            is a lot of blank space . \")\n",
    "    ['This', 'is', 'a', 'lot', 'of', 'blank', 'space']\n",
    "    \n",
    "    >>> tokenize(\"This... (pause)... is a tricky one!\")\n",
    "    ['This', 'pause', 'is', 'a', 'tricky', 'one']\n",
    "    \"\"\"\n",
    "\n",
    "    # ADD YOUR CODE HERE\n",
    "\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f83e8-c7de-49bc-80c2-98e2b32209d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:31.125515Z",
     "start_time": "2024-08-27T13:20:31.120686Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b21c3d69ec4d15fd0b8d729dd9dc9a6",
     "grade": true,
     "grade_id": "cell-76f1cec53c460ece",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db406ec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:31.661986Z",
     "start_time": "2024-08-27T13:20:31.253800Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "169b2090ff72074ae5fc84428974e65d",
     "grade": false,
     "grade_id": "cell-622e328978ed8462",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "evaluate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c03896a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "055ce207c309a6c4f5e1979ee759c2bd",
     "grade": false,
     "grade_id": "cell-1b33e5c097a6752b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2 Normalization\n",
    "\n",
    "In step two, we normalize our tokens. Normalization maps different tokens that refer to the same concept (such as \"COVID 19\" and \"Covid-19\") to a common representation, which can help with vocabulary mismatch.\n",
    "\n",
    "üìù Normalize the tokens below by converting all tokens to lowercase and map these terms `\"covid\", \"sars-cov-2\", and \"coronavirus\"` to `\"covid-19\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdd5dc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:31.795417Z",
     "start_time": "2024-08-27T13:20:31.792613Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41dc4927294063eddca9abc09a6d13f2",
     "grade": false,
     "grade_id": "cell-e8cf37fe9f75a6d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize(tokens: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    >>> normalize([\"Coronavirus\", \"COVID\", \"sars-cov-2\", \"Sars-Cov-1\"])\n",
    "    ['covid-19', 'covid-19', 'covid-19', 'sars-cov-1']\n",
    "    \"\"\"\n",
    "\n",
    "    # ADD YOUR CODE HERE\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c8ebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:31.928939Z",
     "start_time": "2024-08-27T13:20:31.925790Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f7c082e8d4ccd04e31403746a87554c",
     "grade": true,
     "grade_id": "cell-0d21ee89e7ba6485",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034be09c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:32.571797Z",
     "start_time": "2024-08-27T13:20:32.056586Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4049b3183c811b9f639cfcd7550ad98",
     "grade": false,
     "grade_id": "cell-c0bebea1fa4f74f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "evaluate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c4bcc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fe79deff5c35a1a893ac5d08b5532d2",
     "grade": false,
     "grade_id": "cell-30e1071d47c7d299",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.3 Stopping\n",
    "\n",
    "In week-1, we listed the most common words in our index. One observation was that the most common words in a language are not necessarily the ones that carry a lot of information. An early approach to deal with these very common words, such as `as, an, a, the`, was to simply remove them (a step called stopping).\n",
    "\n",
    "üìù Complete the method below to ignore all stopwords contained in the English stopword list of the NLTK library: `nltk.corpus.stopwords.words(\"english\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1312c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:32.828548Z",
     "start_time": "2024-08-27T13:20:32.825460Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "438b5f8870639d18df570ac19d8502e2",
     "grade": false,
     "grade_id": "cell-97390c5f4f448310",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "def stopping(tokens: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    >>> stopping(['each', 'his', 'here', 'other', \"mightn't\", 'mightn', 'not', 'the', 'have', 'same'])\n",
    "    []\n",
    "    >>> stopping([\"hamlet\", \"wonders\", \"to\", \"be\", \"or\", \"not\", \"to\", \"be\"])\n",
    "    ['hamlet', 'wonders']\n",
    "    \"\"\"\n",
    "\n",
    "    # ADD YOUR CODE HERE\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1e6f69aa730df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:32.839457Z",
     "start_time": "2024-08-27T13:20:32.836013Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac7434bf69c510d0df3a22b87f7634d3",
     "grade": true,
     "grade_id": "cell-b79572bc43595245",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test(stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45fc471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:33.314068Z",
     "start_time": "2024-08-27T13:20:32.966703Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb2b676dd270f4440eceac9e15101ee1",
     "grade": false,
     "grade_id": "cell-70ceeae23682145c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "evaluate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e4250",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60064f4ef8eb864b1fe21500dda5d327",
     "grade": false,
     "grade_id": "cell-b8856b280a00c31f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.4 Stemming\n",
    "\n",
    "Lastly, we use stemming as a way to unify word inflections to a common token (e.g., `going` -> `go`).\n",
    "\n",
    "üìù Implement stemming using the [English SnowballStemmer](https://www.nltk.org/api/nltk.stem.SnowballStemmer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ac6719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:33.444578Z",
     "start_time": "2024-08-27T13:20:33.441723Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be3773cec99ae2650e136745e102bfbd",
     "grade": false,
     "grade_id": "cell-ead65f5a5f3fe7aa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "def stemming(tokens: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    >>> stemming([\"universe\", \"universal\"])\n",
    "    ['univers', 'univers']\n",
    "    >>> stemming([\"universe\", \"university\"])\n",
    "    ['univers', 'univers']\n",
    "    >>> stemming([\"likely\", \"like\"])\n",
    "    ['like', 'like']\n",
    "    >>> stemming([\"fairly\", \"fair\"])\n",
    "    ['fair', 'fair']\n",
    "    \"\"\"\n",
    "\n",
    "    # ADD YOUR CODE HERE\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e592c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:33.573774Z",
     "start_time": "2024-08-27T13:20:33.570798Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71f3cdec477bf9b1876744e5e456d58f",
     "grade": true,
     "grade_id": "cell-b64d4fb6c8dcc6c5",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dbc5d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:34.639686Z",
     "start_time": "2024-08-27T13:20:33.703945Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f462d6d2fb8fa1d166b7237e6d29414a",
     "grade": false,
     "grade_id": "cell-10a7b75bae466b81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "evaluate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a0ccff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81270605eac94d6f8ccb40ab4596aab4",
     "grade": false,
     "grade_id": "cell-a46034a84b4dbc12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.5 Inspect the processing steps\n",
    "\n",
    "üìù Now, go back and execute all the preprocessing steps (Kernel > Restart and Run All) and inspect the evaluation results for our three queries. Describe how each preprocessing step affects the following aspects:\n",
    "\n",
    "1. Describe how each step affects the size of our index.\n",
    "2. Describe how each step influences retrieval performance.\n",
    "3. Lastly, evaluate how the query text has changed with the preprocessing and how that might affect our information need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f059ef",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c9ee95c3591d61a2f14799818c8a475",
     "grade": true,
     "grade_id": "cell-4d99e3c22225d460",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">ADD YOUR ANSWER HERE</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858096f5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63e8b5c337aa0c6fc8c880fff9697122",
     "grade": false,
     "grade_id": "cell-75baa84dc86cb886",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part II - Vector Space Model and TF-IDF\n",
    "\n",
    "Let's leave the topic of Covid and go back to the movie dataset from week-1. So far, in this course, we mostly looked at boolean search engines which return results in no particular order. Let's change that and begin by implementing the vector space model using tf-idf weighting. Begin by loading the movie dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a1eed0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:35.292977Z",
     "start_time": "2024-08-27T13:20:34.894424Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8c6cf5aa891af8d681c4c4a7ba7d2c4",
     "grade": false,
     "grade_id": "cell-4a9eda9428e4f5f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_movies(\n",
    "        url: str = \"https://raw.githubusercontent.com/irlabamsterdam/uva-ir0-assignments/main/data/netflix.csv\"\n",
    "):\n",
    "    df = pd.read_csv(url)\n",
    "    df = df.fillna(\"\")\n",
    "    df[\"genres\"] = df[\"genres\"].str.split(\"|\")\n",
    "    df[\"directors\"] = df[\"directors\"].str.split(\"|\")\n",
    "    df[\"actors\"] = df[\"actors\"].str.split(\"|\")\n",
    "    return df\n",
    "\n",
    "def movie_tokenizer(text: str) -> List[str]:\n",
    "    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "    tokens = [t for s in nltk.sent_tokenize(text) for t in tokenizer.tokenize(s)]\n",
    "    tokens = [t for t in tokens if not all([c in string.punctuation for c in t])]\n",
    "    return tokens\n",
    "\n",
    "movie_df = load_movies()\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60b964",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6600fa4c806489ebad95327411510e0",
     "grade": false,
     "grade_id": "cell-8d6877c381397fbe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.1 Inverted index with frequency information\n",
    "\n",
    "Vector space models represent each document and query as vectors with an entry for each token in our corpus. In reality, we have millions of tokens in our index, so storing such large vectors (which are typically sparse, containing mostly zeros) is slow and inefficent. Thus, we again turn to an inverted index to efficiently store and retrieve information.\n",
    "\n",
    "üìù Build an inverted index for **movie title and description** that contains the number of occurrences of a token in a document (**term frequency**), the number of (unique) documents each token appears in (**document frequency**), and lastly create one entry in your index to **count the total number of documents** in our corpus (`index[\"total_documents\"]`). The resulting index should have the following structure:\n",
    "\n",
    "```Python\n",
    "{\n",
    "    \"the\": {\n",
    "        \"postings\": [\n",
    "            {\"id\": 1029, \"term_frequency\": 1},\n",
    "            {\"id\": 1038, \"term_frequency\": 1},\n",
    "            {\"id\": 1155, \"term_frequency\": 1},\n",
    "            ...\n",
    "        ]\n",
    "        \"document_frequency\": 4647\n",
    "    },\n",
    "    \"crown\": {\n",
    "        \"postings\": [\n",
    "            {'id': 117, 'term_frequency': 1},\n",
    "            {'id': 505, 'term_frequency': 1},\n",
    "            {'id': 899, 'term_frequency': 1},\n",
    "            ...\n",
    "        ],\n",
    "        \"document_frequency\": 11\n",
    "    },\n",
    "    ...\n",
    "    \"total_documents\": 1234\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "üí° Tip: The \"collections.defaultdict\" and \"collections.Counter\" classes might be helpful in this task.\n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    "‚ö†Ô∏è Note: From now on use the `movie_tokenizer()` method from the cell above to preprocess your documents when creating the index, and NOT your tokenize method from task 1.1.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31048c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:37.233677Z",
     "start_time": "2024-08-27T13:20:35.318324Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36228a04408b062edf57a66d75316dec",
     "grade": false,
     "grade_id": "cell-7898ef1cc1673f0d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def create_index(df: pd.DataFrame) -> Dict[\n",
    "    str, List[int]]:\n",
    "    \"\"\"\n",
    "    >>> index = create_index(movie_df)\n",
    "    >>> index[\"total_documents\"]\n",
    "    6114\n",
    "    \n",
    "    >>> index[\"headspace\"]\n",
    "    {'postings': [{'id': 5074, 'term_frequency': 2}, {'id': 5231, 'term_frequency': 1}, {'id': 5281, 'term_frequency': 2}], 'document_frequency': 3}\n",
    "    \n",
    "    >>> index[\"saul\"]\n",
    "    {'postings': [{'id': 915, 'term_frequency': 4}, {'id': 2117, 'term_frequency': 2}], 'document_frequency': 2}\n",
    "    \n",
    "    >>> index[\"burnham\"]\n",
    "    {'postings': [{'id': 749, 'term_frequency': 3}, {'id': 1250, 'term_frequency': 2}, {'id': 4795, 'term_frequency': 2}, {'id': 5832, 'term_frequency': 2}], 'document_frequency': 4}\n",
    "    \"\"\"\n",
    "    index = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # You can access details for each movie using the row variable:\n",
    "        # E.g., row.id, row.title, row.description\n",
    "        tokens = movie_tokenizer(row.title) + movie_tokenizer(row.description)\n",
    "\n",
    "    # ADD YOUR CODE HERE\n",
    "\n",
    "    return index\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    movie_index = create_index(movie_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45d82e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:41.201966Z",
     "start_time": "2024-08-27T13:20:37.342340Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e6082dae42a9f4c56c085989634d794",
     "grade": true,
     "grade_id": "cell-679becc6819f6477",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test(create_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a55cde5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e547b48f9eae4d72c13e36d41d8ac256",
     "grade": false,
     "grade_id": "cell-4e8eee7d309f22a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.2 TF-IDF\n",
    "\n",
    "üìù Now, let's use the index to build a search engine that returns a list of documents ranked by their tf-idf scores:\n",
    "- Return a list of tuples containing title (you can use the helper `id2title`) and their score, e.g., `[(\"movie A\", 10), (\"movie B\", 9.5),...]`.\n",
    "- Return just the top-k search results sorted by score descendingly, break ties by sorting by title alphabetically\n",
    "- Round all tf-idf scores to 8 decimal places.\n",
    "\n",
    "There are different formulations of tf-idf. For this assignment, we define tf-idf as:\n",
    "\n",
    "#### Term Frequency (TF)\n",
    "Let $f_{t,d}$ be the number of times the term $t$ occurs in document $d$ (`term_frequency` is your index posting list). Then compute the term frequency component as:\n",
    "\n",
    "$\\textrm{tf}(t, d) = 1 + \\ln(f_{t,d})$\n",
    "\n",
    "#### Inverse-Document Frequency (IDF)\n",
    "Let $N_{t}$ be the number of documents that contain the term t (`document_frequency` in your index), and $N$ be the total number of documents in your corpus. Compute the inverse-document frequency as:\n",
    "\n",
    "$\\textrm{idf}(t) = \\ln(\\frac{N}{N_t})$\n",
    "\n",
    "#### Compute document scores\n",
    "Lastly rank all documents by the sum of their tf-idf scores for each term $t$ inside query $q$:\n",
    "\n",
    "$\\textrm{tf-idf}(q, d) = \\sum_{t \\in q} \\textrm{tf}(t, d) * \\textrm{idf}(t)$\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "üí° You can use `log()` to calculate the natural logarithm ln.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "‚ö†Ô∏è Don't group tf-idf scores by title, some movies (with different ids) have the same title!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79868098",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:41.214246Z",
     "start_time": "2024-08-27T12:28:28.626865Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f26787e4c7d7e602b7ab7ca859809453",
     "grade": false,
     "grade_id": "cell-6f5d64c256425777",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a mapping of move ids to their title\n",
    "id2title = movie_df.set_index(\"id\").title.to_dict()\n",
    "\n",
    "\n",
    "def search_tf_idf(index: Dict, tokens: List[str], top_k: int) -> List[\n",
    "    Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    >>> search_tf_idf(movie_index, [\"headspace\"], 3)\n",
    "    [('headspace guide to sleep', 12.90131457), ('headspace unwind you mind', 12.90131457), ('headspace guide to meditation', 7.61972421)]\n",
    "    \n",
    "    >>> search_tf_idf(movie_index, [\"trump\", \"obama\"], 5)\n",
    "    [('trump: an american dream', 11.04120227), ('american factory: a conversation with the obamas', 7.33204214), ('barry', 7.33204214), ('becoming', 7.33204214), ('our great national parks', 7.33204214)]\n",
    "    \n",
    "    >>> search_tf_idf(movie_index, [\"breaking\", \"bad\"], 3)\n",
    "    [('breaking bad', 9.9971137), ('el camino: a breaking bad movie', 9.9971137), ('the road to el camino: behind the scenes of el camino: a breaking bad movie', 9.9971137)]\n",
    "    \"\"\"\n",
    "    titles = []\n",
    "\n",
    "    # ADD YOUR CODE HERE\n",
    "\n",
    "    return titles[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e810778",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:41.214686Z",
     "start_time": "2024-08-27T12:28:32.035856Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b36545a95ea022f4d27f18795acd193",
     "grade": true,
     "grade_id": "cell-39a914b6165d6757",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test(search_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37cc5c1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73520d02233ad06f9926d09a1ca88d24",
     "grade": false,
     "grade_id": "cell-0ad21c44a4498022",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part III - Language Models and Query Likelihood (LM)\n",
    "\n",
    "In this last part, we implement language-model-based retrieval. Language models are probability distributions over a sequence of words. For example, given the entire text of lord of the rings, what is the probability of Gollum saying \"my precious\".\n",
    "\n",
    "If we are just concerned how likely an individual word is given a document collection, we use a unigram model (basically the word frequency dividied by the number of all words in the corpus). But we could also calculate the probability of a word, given the previous word (2-gram) or the previous two words (3-gram). Modern large language models like GPT-4 or LLaMA use deep neural networks to predict the next word conditioned on a whole sequence of tokens. For this assignment, we will focus on the simple unigram model.\n",
    "\n",
    "Let's begin by updating our index to build a language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f3f3a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc3a8167991438480ec0199615fee07f",
     "grade": false,
     "grade_id": "cell-3bcd4ee1fe99ef6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.1 An inverted index for language models\n",
    "\n",
    "üìù Create a new inverted index where the term frequency is now the probability of a word appearing in a document. Let $f_{t,d}$ again be the number of times a token appears in document $d$ and $|d|$ is the length of a document:\n",
    "\n",
    "$\\textrm{tf}(t, d) = \\frac{f_{t,d}}{|d|}$\n",
    "\n",
    "Next, we modify the notion of document frequency and count the number of (non-unique) occurrences of a token in our corpus, divided by the number of all tokens in our corpus (i.e., the length of all documents). For example, how often was the term \"netflix\" used divided by the total number of words across all documents in our corpus.\n",
    "\n",
    "We call this the `corpus_frequency` of a token, which describes how likely a term is overall to be drawn from our document collection. Round all probabilities to 8 decimal places.\n",
    "\n",
    "The resulting index should have the following structure:\n",
    "\n",
    "\n",
    "```Python\n",
    "{\n",
    "    \"crown\": {\n",
    "        \"postings\": [\n",
    "            {'id': 117, 'term_frequency': 0.02273...},\n",
    "            {'id': 505, 'term_frequency': 0.04348...},\n",
    "            {'id': 899, 'term_frequency': 0.01667...},\n",
    "            ...\n",
    "        ],\n",
    "        \"corpus_frequency\": = 0.00005342\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a68ca0b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c27629cb6c0bdceab157a224a46a2d7c",
     "grade": false,
     "grade_id": "cell-8ff0fb62336dd7de",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def create_lm_index(df: pd.DataFrame) -> Dict[\n",
    "    str, List[int]]:\n",
    "    \"\"\" \n",
    "    >>> index = create_lm_index(movie_df)\n",
    "    >>> index[\"headspace\"]\n",
    "    {'postings': [{'id': 5074, 'term_frequency': 0.08333333}, {'id': 5231, 'term_frequency': 0.01960784}, {'id': 5281, 'term_frequency': 0.07407407}], 'corpus_frequency': 2.013e-05}\n",
    "    \n",
    "    >>> index[\"saul\"]\n",
    "    {'postings': [{'id': 915, 'term_frequency': 0.05882353}, {'id': 2117, 'term_frequency': 0.05}], 'corpus_frequency': 2.416e-05}\n",
    "    \n",
    "    >>> index[\"burnham\"]\n",
    "    {'postings': [{'id': 749, 'term_frequency': 0.06521739}, {'id': 1250, 'term_frequency': 0.05405405}, {'id': 4795, 'term_frequency': 0.07142857}, {'id': 5832, 'term_frequency': 0.04166667}], 'corpus_frequency': 3.624e-05}\n",
    "    \"\"\"\n",
    "    index = {}\n",
    "\n",
    "    # Example of how to iterate over a dataframe\n",
    "    for i, row in df.iterrows():\n",
    "        # You can access details for each movie using the row variable:\n",
    "        # E.g., row.id, row.title, row.description\n",
    "        tokens = movie_tokenizer(row.title) + movie_tokenizer(row.description)\n",
    "\n",
    "    # ADD YOUR CODE HERE\n",
    "\n",
    "    return index\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lm_index = create_lm_index(movie_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe5560",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6ef684900dbe70c93dd84f0ff81fcbf",
     "grade": true,
     "grade_id": "cell-5ccb2fe84a753c0c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test(create_lm_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef8e75",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f39a93affc75b2d3228da834e2e3d6f",
     "grade": false,
     "grade_id": "cell-054d2cfba445e6d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.2 Language model - Query likelihood search\n",
    "\n",
    "Next, let's implement the query likelihood model. We want to use our unigram language model to predict how likely a document is for a given query $P(d \\mid q)$. Using Bayes' rule we can see that the probability of a document being relevant $P(d \\mid q)$ is proportional to the likelihood of a query being generated from the document: $P(q \\mid d)$. Let's explain this step by step:\n",
    "\n",
    "First, we remember Bayes' rule:\n",
    "\n",
    "$P(d \\mid q) = \\normalsize \\frac{P(q \\mid d) P(d)}{P(q)}$\n",
    "\n",
    "In our case $P(q)$ is a normalizing constant that is the same for all documents, thus it does not influence our ranking and we can drop it. $P(d)$ describes how likely each document is in our corpus. If we assume that all documents are equally likely, we can also drop this part. Thus it remains that:\n",
    "\n",
    "$P(d \\mid q) \\propto P(q \\mid d)$\n",
    "\n",
    "These assumptions makes our life much easier and what remains is to calculate the joint probability of the query terms occuring in each document (i.e. the term-frequency calculated in our index above):\n",
    "\n",
    "$P(q \\mid d) = \\prod_{t \\in q} P(t \\mid d) = \\textrm{tf}(t, d)$\n",
    "\n",
    "\n",
    "üìù Implement the query-likelihood model by ranking each document the joint probability of all query terms occurring in a document.\n",
    "- If a document does not contain a query term, assume that: $P(q \\mid d) = 0$.\n",
    "- Return only the top-k documents and break ties by sorting alphabetically by title.\n",
    "- The result is a list of tuples containing movie title and probability (rounded to 8 places)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40d5e63",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba91355152cc83bd428b5a41ed43796b",
     "grade": false,
     "grade_id": "cell-a9f4d38f8173d46c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def query_likelihood(index: Dict, tokens: List[str], top_k: int) -> List[\n",
    "    Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    >>> query_likelihood(lm_index, ['the', 'crown'], 3)\n",
    "    [('the crown', 0.00619253), (\"the king's affection\", 0.00312175), ('a christmas prince: the royal wedding', 0.00135031)]\n",
    "    \n",
    "    >>> query_likelihood(lm_index, ['queen', 'crown'], 2)\n",
    "    [('the crown', 0.00056296), ('a christmas prince: the royal wedding', 0.0001929)]\n",
    "    \n",
    "    >>> query_likelihood(lm_index, [\"queer\", \"eye\"], 4)\n",
    "    [(\"queer eye: we're in japan!\", 0.00694444), ('queer eye', 0.0016), ('queer eye: brazil', 0.0016), ('queer eye germany', 0.00118906)]\n",
    "    \"\"\"\n",
    "    titles = []\n",
    "\n",
    "    # ADD YOUR CODE HERE\n",
    "\n",
    "    return titles[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d74ac9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5e2b4610d63a58d0697d451d9e5eaff",
     "grade": true,
     "grade_id": "cell-58a0843c31f49ab7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test(query_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94353b7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a407429ae9766b1fa4224a1e0bb8e15",
     "grade": false,
     "grade_id": "cell-0992d645557ddea4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.3 Smoothed Query Likelihood\n",
    "\n",
    "Lastly, the above ranking model is clearly not ideal. Missing only one query term is leading to a joint probability of 0. This problem is usually mitigated using smoothing, the idea of assigning each term a minimum probability even if they are not mentioned in the document. This could be a fixed probability for each term, or more commonly, a global term probability (e.g., our corpus frequency calculated in the index) which is linearly interpolated with the document-level probability:\n",
    "\n",
    "$P(q \\mid d) = \\prod_{t \\in q} \\alpha P(t \\mid c) + (1 - \\alpha) P(t \\mid d)$\n",
    "\n",
    "Where $\\alpha$ is a hyperparameter, such as $\\alpha = 0.1$ and $ P(t \\mid c)$ is our corpus-level probability of a token. This approach is called linear or **Jelinek-Mercer smoothing**.\n",
    "\n",
    "\n",
    "üìù Copy your solution from task 3.2 above and add linear smoothing. Note that you need to retrieve all documents that contain at least one query term in this task (similar to an OR search). Sort the output as before and return only top_k items with the final scores rounded to 8 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb67df",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9efcd344c869ea58e6a67fa3f7dd20b2",
     "grade": false,
     "grade_id": "cell-6fdc03dcd1331d26",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def smooth_query_likelihood(index: Dict, tokens: List[str], top_k: int,\n",
    "                            alpha: float = 0.1) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    >>> smooth_query_likelihood(lm_index, [\"queen\", \"crown\"], top_k=5, alpha=0.1)    \n",
    "    [('the crown', 0.00045678), ('a christmas prince: the royal wedding', 0.00015655), ('hero mask', 7.5e-07), (\"the king's affection\", 5.8e-07), ('babamƒ±n ceketi', 3.1e-07)]\n",
    "    \n",
    "    >>> smooth_query_likelihood(lm_index, [\"queer\", \"eye\"], top_k=4, alpha=0.5)\n",
    "    [(\"queer eye: we're in japan!\", 0.00173905), ('queer eye', 0.00040141), ('queer eye: brazil', 0.00040141), ('queer eye germany', 0.00029848)]\n",
    "    \n",
    "    >>> smooth_query_likelihood(lm_index, [\"queer\", \"eye\"], top_k=4, alpha=0.9)\n",
    "    [(\"queer eye: we're in japan!\", 7.05e-05), ('queer eye', 1.651e-05), ('queer eye: brazil', 1.651e-05), ('queer eye germany', 1.233e-05)]\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # ADD YOUR CODE HERE\n",
    "\n",
    "    return results[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867535d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ee2b29f0905eaf2d84d33622703e456",
     "grade": true,
     "grade_id": "cell-789e10bbf645c09b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test(smooth_query_likelihood)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
