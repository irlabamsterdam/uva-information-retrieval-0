{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b155a041",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Before you turn this assignment in, make sure everything runs as expected by going to the menubar and running: \n",
    "\n",
    "**Kernel $\\rightarrow$ Restart & Run All**\n",
    "\n",
    "Please replace all spots marked with `# ADD YOUR CODE HERE` or `ADD YOUR ANSWER HERE`.\n",
    "\n",
    "And start by filling in your name and student_id below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c638ab2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "STUDENT_ID = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9e5bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert len(NAME) > 0, \"Please fill in your name\"\n",
    "assert len(STUDENT_ID) > 0, \"Please fill in your student id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d57ae88",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef108c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9955be3119bd34782a61a8414baa3075",
     "grade": false,
     "grade_id": "cell-215984d47d208409",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "dependencies"
    ]
   },
   "outputs": [],
   "source": [
    "# If you encounter import issues with scipy,\n",
    "# please make sure to update Gensim to 4.3.3\n",
    "%pip install --upgrade --quiet gensim==4.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa61b4e4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "139ed06528c5d17d08902b9b26528771",
     "grade": false,
     "grade_id": "cell-186e1e44f0bd2d60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import doctest\n",
    "\n",
    "import gensim.downloader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from html import unescape\n",
    "from typing import Callable, List, Dict , Tuple\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908fa9ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa43c23dded9310f8e021eeb364a5d38",
     "grade": false,
     "grade_id": "cell-4275800b83eca0b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test(fn: Callable):\n",
    "    if __name__ == \"__main__\":\n",
    "        doctest.run_docstring_examples(fn, globals(), verbose=True, name=fn.__name__, optionflags=doctest.ELLIPSIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2890506",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1819d01cefa330a1669d07f0ad8bc9c2",
     "grade": false,
     "grade_id": "cell-b4d821343ae97089",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Week 5 - Word Embeddings & Recommender Systems\n",
    "\n",
    "Welcome to the last assignment of Zoekmachines! üëã\n",
    "\n",
    "In the first part of this assignment, we look into word embeddings covered in last week's lecture.\n",
    "\n",
    "Part two and three cover recommender systems, the basis for systems that recommend our movies, music, recipes, and even news. So far in this course, we have looked into using the textual content of queries and documents to find relevant items. For example, recommending a news article because of its high tf-idf match with something you previously engaged with would be a content-based recommender system. Many of the techniques we have learned in this course are helpful for this approach. This week, however, we will look into finding similar items not by inspecting their textual content but rather from their user interaction patterns. This is called the collaborative filtering approach to recommendation.\n",
    "\n",
    "As always, for any questions, problems, or feedback please contact your TA. Good luck with the assignment!\n",
    "\n",
    "\n",
    "### Resources\n",
    "- üìö [Neighborhood-based Recommendation Methods - Desrosiers and Karypis, RecSys Handbook Chapter 4.2](https://www.cse.iitk.ac.in/users/nsrivast/HCC/Recommender_systems_handbook.pdf)\n",
    "\n",
    "- üìö [Gensim Word2Vec tutorial](https://rare-technologies.com/word2vec-tutorial/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e47b17",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ade26ae85a4850c2821dd33158576edf",
     "grade": false,
     "grade_id": "cell-a4260b5da3e51491",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part I - Word Embeddings\n",
    "\n",
    "In last week's lecture, you learned about semantic matching and word embeddings. Word embeddings took off in the NLP community in 2013 with the introduction of the Word2Vec model, which is a neural network trained to predict the missing word given its surrounding context words (or the other way around: given a word, predict the context words).\n",
    "\n",
    "Just by executing this rather simple task on a large amount of documents, the model learned surprisingly powerful word representations. The author's discovered, that Word2Vec embeddings encoded:\n",
    "\n",
    "* Syntactic similarities bewteen words, e.g.: `[go, went, gone]` or `[kind, kinder, kindest]`\n",
    "* Semantic relationships, e.g.: `[brother, sister, grandson, granddaughter]`, [`germany`, `germans`, `netherlands`, `dutch`]\n",
    "* And they encoded analogies in the latent space, e.g.: `woman` is to `man`, as `queen` is to `king`.\n",
    "\n",
    "A word of caution: While these anaolgies computed using vector arithmetics (adding or subtracting word vectors), were quite impressive, they also often revealed and encoded stereotypes that were present in the training dataset.\n",
    "\n",
    "With that said, let's explore word embeddings a bit. First, let's download a small word embedding corpus that was trained on news articles from the early 2000s. Throughout these tasks, we will use the [Gensim library](https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.html) (which is also quite useful for using more advanced topic models than LSI), feel free to use all available API methods in the following tasks.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "üí° The word embeddings will be downloaded into ~/gensim-data in your home directory. Feel free to delete it right after this task.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a7cbc5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a854b8ce345f88491239e281b572ef8e",
     "grade": false,
     "grade_id": "cell-12ffe3acdf057d62",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = gensim.downloader.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a605a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e4ba7cceb9f77a12ebd5d8e1afc34f5",
     "grade": false,
     "grade_id": "cell-550927c43afea41f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1 Nearest neighbors\n",
    "\n",
    "üìù As your first task, find the **top-n most similar terms** to a **list of query terms** using [Gensim](https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.html):\n",
    "\n",
    "- Most similar here means words with the highest cosine similarity to the query vector.\n",
    "- If multiple query terms are given, find words with the similarity to the **average word vector of all query terms**.\n",
    "- Return the list of words in order of similarity but without the similarity scores themselves.\n",
    "- The query terms themselves should not appear in the list of most similar terms.\n",
    "\n",
    "### Example\n",
    "The five closest terms to `[\"hangover\"]` are `['fright', 'headache', 'letdown', 'mania', 'affliction']`,\n",
    "\n",
    "and the closest terms to `[\"hangover\", \"movie\"]` are `['hollywood', 'movies', 'blockbuster', 'sequel', 'film']`.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "üí° You can access a vector of a word using model[\"movie\"]. Inspect the Gensim API to find ways to compute cosine similarity and perform nearest neighbor search.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79608266",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f18274a3d585dcf6fc092460c82ce706",
     "grade": false,
     "grade_id": "cell-f12ed9ea9662c641",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_most_similar(model: KeyedVectors, query_terms: List[str], top_k=5):\n",
    "    \"\"\"\n",
    "    >>> find_most_similar(model, [\"hangover\"], top_k=3)\n",
    "    ['fright', 'headache', 'letdown']\n",
    "    \n",
    "    >>> find_most_similar(model, [\"hangover\", \"movie\"], top_k=8)\n",
    "    ['hollywood', 'movies', 'blockbuster', 'sequel', 'film', 'nightmare', 'comedy', 'horror']\n",
    "    \n",
    "    >>> find_most_similar(model, [\"clinton\"], top_k=3)\n",
    "    ['bush', 'obama', 'gore']\n",
    "    \n",
    "    >>> find_most_similar(model, [\"hillary\", \"clinton\"], top_k=5)\n",
    "    ['rodham', 'obama', 'barack', 'bush', 'mccain']\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # ADD YOUR CODE HERE\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6aedbc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e40bbd59738a2f9fdd2f8191dfeba54",
     "grade": true,
     "grade_id": "cell-440441b6ebdf8f2b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test(find_most_similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4093081d",
   "metadata": {},
   "source": [
    "## 1.2 Analogies\n",
    "\n",
    "üìù In this second tasks, we will explore the word analogies encoded in our word vectors using vector arithmetics.\n",
    "\n",
    "- Given an example pair of words (e.g., `[\"man\", \"woman\"]`), find the anaolgy for a new term (e.g., `[\"king\", \"?\"]`).\n",
    "- Return the top answer for your analogy.\n",
    "\n",
    "### Resources\n",
    "\n",
    "üìö [Gensim Word2Vec tutorial](https://rare-technologies.com/word2vec-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7879fa7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aeec670a92c45338817aee2c666f3320",
     "grade": false,
     "grade_id": "cell-896f4d393a9c9d40",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_analogy(model: KeyedVectors, word_pair: Tuple[str, str], term):\n",
    "    \"\"\"\n",
    "    >>> find_analogy(model, word_pair=[\"man\", \"woman\"], term=\"king\")\n",
    "    'queen'\n",
    "    \n",
    "    >>> find_analogy(model, word_pair=[\"democrat\", \"republican\"], term=\"obama\")\n",
    "    'bush'\n",
    "    \n",
    "    >>> find_analogy(model, word_pair=[\"go\", \"going\"], term=\"walk\")\n",
    "    'walking'\n",
    "    \n",
    "    >>> find_analogy(model, word_pair=[\"europe\", \"euro\"], term=\"america\")\n",
    "    'dollar'\n",
    "    \n",
    "    >>> find_analogy(model, word_pair=[\"germany\", \"berlin\"], term=\"netherlands\")\n",
    "    'amsterdam'\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    \n",
    "    # ADD YOUR CODE HERE\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd834c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8da0264302b535299f265bb8a6e8506",
     "grade": true,
     "grade_id": "cell-ddd4d80161caf93d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test(find_analogy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb17aec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae04b9d42e5b8a7ffbb5d17a1d2653a3",
     "grade": false,
     "grade_id": "cell-6d3870748e75a948",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part II - User-User Collaborative Filtering\n",
    "\n",
    "Next, we will move to recommender systems for part II and III of this assignment, where we are building a recommender system for books. First, we look into a user-user collaborative filtering approach, the idea that users might like content that users with a similar preference previously already enjoyed. Specifically, we look into nearest neighbor collaborative filtering, a very basic approach to solve this problem. Essentially: Given a user, find users that are very similar to them (called neighbors) and recommend content that these other users enjoyed but our user has not engaged with.\n",
    "\n",
    "For this assignment, we use a public book dataset with ‚âà94k real user ratings for ‚âà13k books on a scale from 1 - 11 (you can treat zeros as missing values throughout this exercise). Let's begin by downloading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2bb851",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b9c609589dd3db18d99bea2b1b462fc",
     "grade": false,
     "grade_id": "cell-ace4716f767730d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(url: str = \"https://raw.githubusercontent.com/irlabamsterdam/uva-ir0-assignments/main/data/rating.csv\") -> pd.DataFrame:\n",
    "    return pd.read_csv(url)\n",
    "\n",
    "def get_id2title(df: pd.DataFrame) -> Dict[int, str]:\n",
    "    return df.set_index(\"item_id\").title.to_dict()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data()\n",
    "    id2title = get_id2title(df)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eac02a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61e5fbd447b0d450dec69dc20f2856b8",
     "grade": false,
     "grade_id": "cell-820f3c5e873ee295",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "\n",
    "## 2.1 The user-item-rating matrix\n",
    "\n",
    "We begin with a classic way to represent rating data, as a 2D matrix between users and items.\n",
    "\n",
    "üìù Transform our dataset into a rating matrix (of shape users x items), containing a row for each user and a column for each item. Insert the ratings as entries in this 2D array. If a user has not rated a book, the entry should be zero.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "üí° Pandas's \"pivot_table\" operation might come in handy to speed up this transformation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6fa9b9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26278920216abe5e7ef9230e73daa90a",
     "grade": false,
     "grade_id": "cell-a44490682a62c425",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_user_item_ratings(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    >>> user_item_ratings = get_user_item_ratings(df)\n",
    "    >>> user_item_ratings.shape\n",
    "    (1710, 13053)\n",
    "    >>> user_item_ratings[0, [320, 444, 1288, 1406, 1774]]\n",
    "    array([11.,  8.,  1.,  1.,  1.])\n",
    "    >>> user_item_ratings[1709, [10703, 10823, 11208, 12678, 12937]]\n",
    "    array([9., 8., 1., 1., 9.])\n",
    "    >>> user_item_ratings[[0, 1, 2, 3, 4], [1881, 9433, 18, 9964, 888]]\n",
    "    array([ 8.,  7., 10.,  1., 10.])\n",
    "    \"\"\"\n",
    "    user_item_ratings = np.array([[]])\n",
    "    \n",
    "    # ADD YOUR CODE HERE\n",
    "    return user_item_ratings.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8ac64",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "baace48159a632baed4f78e2d75ab6e4",
     "grade": true,
     "grade_id": "cell-63e942454b581502",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test(get_user_item_ratings)\n",
    "    user_item_ratings = get_user_item_ratings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30e2d0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd1673dac44e8d648960ee27e8f2b140",
     "grade": false,
     "grade_id": "cell-5d48f8d916692862",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 2.2 Similarity Measures\n",
    "\n",
    "Let's begin by defining a similarity measure between users. How could we compute the similarity between two users just by using a vector representation of their previous ratings? One popular option is to compute the cosine of the angle between both vectors, i.e., the [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) that we used during the feature engineering last week. Another prevalent option is to compute the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient). But what is the main difference between both?\n",
    "\n",
    "üìù Inspect the four users below who rated the same three items. We compute the cosine similarity between the users and the Pearson correlation coefficient. Describe similarities and differences between the output of both metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86edb30",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bfd5413c2f6a104ccf9da8fe8fe527b",
     "grade": false,
     "grade_id": "cell-f28205c0df3e0caa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    user_a = np.array([1, 5, 10])\n",
    "    user_b = np.array([1, 2, 3])\n",
    "    user_c = np.array([7, 8, 9])\n",
    "    user_d = np.array([10, 5, 1])\n",
    "\n",
    "    example_rating_matrix = np.vstack([\n",
    "        user_a,\n",
    "        user_b,\n",
    "        user_c,\n",
    "        user_d\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded0895",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "338ba221472a586d43332c45f8e970bb",
     "grade": false,
     "grade_id": "cell-6e15481b2f7a79d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Cosine similarity between user ratings:\")\n",
    "    print(cosine_similarity(example_rating_matrix).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4dd29",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f53c09b6304091ba1b3b2b992053e4e",
     "grade": false,
     "grade_id": "cell-f636bbd477f11fb5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Pearson correlation coefficient between user ratings:\")\n",
    "    print(np.corrcoef(example_rating_matrix).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e09cb54",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e32ee56e71fcdc4ae5e816719b1db6bb",
     "grade": true,
     "grade_id": "cell-02111c33bfe5dbe0",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">ADD YOUR ANSWER HERE</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4504cea2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f8b4a2e13c6be0a9f8a0810f690b739",
     "grade": false,
     "grade_id": "cell-db309a9992a2fa02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 2.3 User-User Similarity Matrix\n",
    "\n",
    "Now, let's actually compute the similarity between users in our dataset.\n",
    "\n",
    "üìù Complete the method below and return a matrix of size (user x user) that contains the pearson correlation between all users in our user-item-rating matrix. Lastly, each user is the most similar to themselves (see the 1.0 score on the diagonal above). Avoid this by setting the similarity of a user to themselves to zero in your matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c259f03",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f07dc95034f9ef93fcad61334fec6681",
     "grade": false,
     "grade_id": "cell-9cfe964675c107dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_user_similarity(user_item_ratings: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    >>> user_similarity = get_user_similarity(user_item_ratings)\n",
    "    \n",
    "    # Check that the resulting matrix is of size user x user\n",
    "    >>> user_similarity.shape\n",
    "    (1710, 1710)\n",
    "    \n",
    "    # Check that users are not similar to themselves\n",
    "    >>> (np.diag(user_similarity) == np.zeros((1710))).all()\n",
    "    True\n",
    "    \n",
    "    # Check that similarty matrix does not contain invalid values\n",
    "    >>> np.isnan(user_similarity).sum() == 0\n",
    "    True\n",
    "    \n",
    "    # Check pearson correlation\n",
    "    >>> test_user_item_ratings = np.array([[1, 5, 11], [9, 10, 11], [4, 3, 2]])\n",
    "    >>> expected_user_similarity = np.array([[ 0.,  1., -1.], [ 1.,  0., -1.], [-1., -1.,  0.]])\n",
    "    >>> actual_user_similarity = get_user_similarity(test_user_item_ratings).round(1)\n",
    "    >>> np.array_equal(actual_user_similarity, expected_user_similarity)\n",
    "    True\n",
    "    \"\"\"\n",
    "    user_similarity = np.array([[]])\n",
    "    \n",
    "    # ADD YOUR CODE HERE\n",
    "    \n",
    "    return user_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f18839",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "792436ff2160be3a786e76dba3e28315",
     "grade": true,
     "grade_id": "cell-ec141ef39a7c84c8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test(get_user_similarity)\n",
    "    user_similarity = get_user_similarity(user_item_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ea144",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "988726197c8e40bb75153eeb4e3a87b3",
     "grade": false,
     "grade_id": "cell-b582d3c02671aa9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 2.4 Finding K-Nearest Neighbors\n",
    "\n",
    "Next, let's use our similarity matrix to find the most related users (neighbors) to a given user we want to recommend a book to.\n",
    "\n",
    "üìù Find the `k` nearest users with the highest pearson correlation with a given user. Note that you can access the user_similarity matrix that we just created using the `similarity_matrix` parameter in the function below. Return an array with the ids of neighboring users `neighbor_ids` (sorted by decreasing similarity) as well as an array of their `similarities`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b622d7b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3834cb75ce8675c7b52f0e6bc39f2795",
     "grade": false,
     "grade_id": "cell-2325e93b8823e2bb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_nearest_neighbors(similarity_matrix: np.ndarray, user_id: int, k: int = 100) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    # Test that user is not part of the neighbors array\n",
    "    >>> test_neighbors, test_similarity = get_nearest_neighbors(user_similarity, user_id=20, k=100)\n",
    "    >>> all(test_neighbors != 20)\n",
    "    True\n",
    "    \n",
    "    >>> test_neighbors, test_similarity = get_nearest_neighbors(user_similarity, user_id=0, k=3)\n",
    "    >>> test_neighbors\n",
    "    array([ 430, 1586,  127])\n",
    "    >>> test_similarity.round(3)\n",
    "    array([0.229, 0.175, 0.167])\n",
    "    \n",
    "    >>> test_neighbors, test_similarity = get_nearest_neighbors(user_similarity, user_id=1500, k=5)\n",
    "    >>> test_neighbors\n",
    "    array([ 475,  744,   18, 1057, 1416])\n",
    "    >>> test_similarity.round(3)\n",
    "    array([0.152, 0.132, 0.12 , 0.114, 0.11 ])\n",
    "    \"\"\"\n",
    "    neighbor_ids = np.array([])\n",
    "    similarities = np.array([])\n",
    "    \n",
    "    # ADD YOUR CODE HERE\n",
    "    \n",
    "    return neighbor_ids, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32fd029",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed077b4666f9100ad2fbe972b5a772b3",
     "grade": true,
     "grade_id": "cell-16c7a34d95965f7f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test(get_nearest_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30016893",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5364bca026e657ed1157f8e38aa6185d",
     "grade": false,
     "grade_id": "cell-094b322c871b2fd5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 2.5 Mean Rating Recommendations\n",
    "\n",
    "We should be all set now to actually make some recommendations. The simplest KNN-based collaborative filtering method is just to compute the average item ratings of our nearest neighbors and return them as a sorted list.\n",
    "\n",
    "Let $n \\in N$ be a neighbor in our set of nearest neighbors $N$ for a given user. For each item in our dataset $i$ compute the average rating of all neighbors. If a neighbor did not rate an item consider their rating as $0$.\n",
    "\n",
    "$\\text{rating(i)} = \\frac{1}{|N|} \\sum_{n \\in N} r_{i,n}$\n",
    "\n",
    "üìù Complete the method below and compute the top `n_results` book recommendations for a given user. Rank the recommendations by the average rating of the closest k neighbors. As in previous weeks, return a list of tuples containing the book title and the ranked score (rounded to 4 decimal places), break ties by sorting alphabetically by title. Lastly, ensure that your results do not contain books that the user already has rated. Only use the user_item_ratings matrix and do not access the original dataframe to fetch the user's history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dbe4a7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e6545c126b04a1b6f4cc9e61e73265d",
     "grade": false,
     "grade_id": "cell-56a86abf869471e8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mean_rating_recommendations(\n",
    "    user_item_ratings: np.ndarray,\n",
    "    similarity_matrix: np.ndarray,\n",
    "    user_id: int,\n",
    "    k_neighbors: int,\n",
    "    n_results: int,\n",
    "    id2title: Dict[int, str]\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    # Test that recommendations do not contain books from the user's history\n",
    "    >>> test_recommendations = get_mean_rating_recommendations(user_item_ratings, user_similarity, 1, k_neighbors=1, n_results=3, id2title=id2title)\n",
    "    >>> user_history = [('Harry Potter and the Chamber of Secrets (Book 2)', 11.0), ('Harry Potter and the Goblet of Fire (Book 4)', 11.0), ('Harry Potter and the Prisoner of Azkaban (Book 3)', 11.0)]\n",
    "    >>> assert test_recommendations != user_history\n",
    "    \n",
    "    >>> get_mean_rating_recommendations(user_item_ratings, user_similarity, 971, k_neighbors=10, n_results=3, id2title=id2title)\n",
    "    [('Anne of the Island', 2.1), (\"Anne's House of Dreams\", 2.0), ('Holes (Yearling Newbery)', 2.0)]\n",
    "    \n",
    "    >>> get_mean_rating_recommendations(user_item_ratings, user_similarity, 971, k_neighbors=50, n_results=3, id2title=id2title)\n",
    "    [('The Lovely Bones: A Novel', 0.9), ('Eyes of the Dragon', 0.76), ('The Queen of the Damned (Vampire Chronicles (Paperback))', 0.74)]\n",
    "    \n",
    "    >>> get_mean_rating_recommendations(user_item_ratings, user_similarity, 1009, k_neighbors=50, n_results=3, id2title=id2title)\n",
    "    [('The Da Vinci Code', 1.26), ('Killing Dance (Anita Blake Vampire Hunter (Paperback))', 0.94), ('Cause of Death', 0.78)]\n",
    "    \n",
    "    >>> get_mean_rating_recommendations(user_item_ratings, user_similarity, 500, k_neighbors=50, n_results=5, id2title=id2title)\n",
    "    [('The Lovely Bones: A Novel', 1.68), ('Good in Bed', 1.56), ('A Bend in the Road', 1.1), ('Message in a Bottle', 0.88), (\"Suzanne's Diary for Nicholas\", 0.8)]\n",
    "    \"\"\"\n",
    "    titles = []\n",
    "    \n",
    "    # ADD YOUR CODE HERE\n",
    "    \n",
    "    return titles[:n_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e6f17",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1dcd5771f9767b89eea93c7ea373a7c",
     "grade": true,
     "grade_id": "cell-3d662916d5b3d1b9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test(get_mean_rating_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad298b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfbafc4e3a46ba18bdcc65aa1e7456a8",
     "grade": false,
     "grade_id": "cell-6ce2405e4742a57a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 2.6 Similarity-weighted Rating Recommendations\n",
    "\n",
    "The method above is quite simple. Find a group of similar users and recommend their overall favorite books. However, in the method above, we treat all neighbors the same regardless of their degree of similarity. But intuitively, users that are more similar to me should have a higher impact on my recommendations than the ones with a very different taste. Thus, let's introduce similarity weighted recommendations.\n",
    "\n",
    "Let $s_n$ be the similarity of a neighbor with our current user. We compute a weighted average by weighting each neighbor's rating with their similarity to our user:\n",
    "\n",
    "$\\text{rating(i)} = \\large\\frac{\\sum_{n \\in N} s_{n} \\cdot r_{i,n}}{\\sum_{n \\in N} |s_{n}|}$\n",
    "\n",
    "\n",
    "Note that we normalize by the sum of all similarities in the denominator. Given that the Pearson correlation can be negative, we use the absolute similarity value in the denominator here.\n",
    "\n",
    "üìù Implement the similarity weighted user-user recommendation below. As before, return the top n results with title and score (breaking score ties by title ascendingly). Ensure not to return books that the user has already rated before and lastly, round all returned scores to 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1027f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99832bf231467beb5bbb17327c424886",
     "grade": false,
     "grade_id": "cell-1ba3ca030e449b01",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_weighted_rating_recommendations(\n",
    "    user_item_ratings: np.ndarray,\n",
    "    similarity_matrix: np.ndarray,\n",
    "    user_id: int,\n",
    "    k_neighbors: int,\n",
    "    n_results: int,\n",
    "    id2title: Dict[int, str]\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    # Test that recommendations do not contain books from the user's history\n",
    "    >>> test_recommendations = get_weighted_rating_recommendations(user_item_ratings, user_similarity, 971, k_neighbors=1, n_results=3, id2title=id2title)\n",
    "    >>> user_history = [('Harry Potter and the Chamber of Secrets (Book 2)', 11.0), ('Harry Potter and the Goblet of Fire (Book 4)', 11.0), ('Harry Potter and the Prisoner of Azkaban (Book 3)', 11.0)]\n",
    "    >>> assert test_recommendations != user_history\n",
    "    \n",
    "    >>> get_weighted_rating_recommendations(user_item_ratings, user_similarity, 971, k_neighbors=10, n_results=3, id2title=id2title)\n",
    "    [('Anne of the Island', 1.8494), ('Holes (Yearling Newbery)', 1.8016), (\"Anne's House of Dreams\", 1.7161)]\n",
    "    \n",
    "    >>> get_weighted_rating_recommendations(user_item_ratings, user_similarity, 971, k_neighbors=50, n_results=3, id2title=id2title)\n",
    "    [('The Lovely Bones: A Novel', 0.901), ('Eyes of the Dragon', 0.8939), ('The Queen of the Damned (Vampire Chronicles (Paperback))', 0.7903)]\n",
    "    \n",
    "    >>> get_weighted_rating_recommendations(user_item_ratings, user_similarity, 50, k_neighbors=50, n_results=3, id2title=id2title)\n",
    "    [('The Firm', 1.1842), ('To Kill a Mockingbird', 0.7558), ('The Lovely Bones: A Novel', 0.7126)]\n",
    "    \n",
    "    >>> get_weighted_rating_recommendations(user_item_ratings, user_similarity, 1599, k_neighbors=500, n_results=3, id2title=id2title)\n",
    "    [('Fahrenheit 451', 1.0806), ('Jurassic Park', 0.7894), ('Fear and Loathing in Las Vegas : A Savage Journey to the Heart of the American Dream', 0.7115)]\n",
    "    \"\"\"\n",
    "    titles = []\n",
    "    \n",
    "    # ADD YOUR CODE HERE\n",
    "    \n",
    "    return titles[:n_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b50149e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0192d2e3ead8840596d1ba1545662c41",
     "grade": true,
     "grade_id": "cell-88def009a18680f0",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test(get_weighted_rating_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0360bca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5c8f28af9bc53d69519b897eb02e855",
     "grade": false,
     "grade_id": "cell-8f22b364c02f3896",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Part III Item-Item Collaborative Filtering\n",
    "\n",
    "In the previous part, we looked at user-user relationships and recommended books that people similar to us also enjoyed. In this part, we look at item-item relationships to recommend books that are similar to what we enjoyed in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dc476a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc156d19f16282b0a2ad6040ceaef668",
     "grade": false,
     "grade_id": "cell-cf3dc9b02245d922",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 3.1 Item-Item Similarity Matrix\n",
    "Let's begin again with our user-item-rating matrix. But this time, compute the similarity between all items so that the returning matrix is of shape (items x items).\n",
    "\n",
    "üìù Complete the method below and return a matrix of size (item x item) that contains the Pearson correlation between all items in our user-item-rating matrix. Set the similarity of an item to itself to zero.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "üí° Tip: Try out what flipping our user_item_ratings matrix over the diagonal does to the similarity calculation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fd142",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc1e7308bfae445a603814febc31cb23",
     "grade": false,
     "grade_id": "cell-03f3ed24e37ac4cc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_item_similarity(user_item_ratings: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    # To make sure that we can test from with CodeGrade, we only take a third of the user_item_ratings\n",
    "    >>> item_similarity = get_item_similarity(user_item_ratings[:, ::3])\n",
    "    \n",
    "    # Check that the resulting matrix is of size user x user\n",
    "    >>> item_similarity.shape\n",
    "    (4351, 4351)\n",
    "    \n",
    "    # Check that users are not similar to themselves\n",
    "    >>> (np.diag(item_similarity) == np.zeros((4351))).all()\n",
    "    True\n",
    "    \n",
    "    # Check that similarty matrix does not contain invalid values\n",
    "    >>> np.isnan(item_similarity).sum() == 0\n",
    "    True\n",
    "    \n",
    "    # Check pearson correlation\n",
    "    >>> test_user_item_ratings = np.array([[1, 5, 11, 20], [9, 10, 11, 12], [4, 3, 2, 1]])\n",
    "    >>> expected_item_similarity = np.array([[ 0. ,  0.8,  0.1, -0.3], [ 0.8,  0. ,  0.7,  0.4], [ 0.1,  0.7,  0. ,  0.9], [-0.3,  0.4,  0.9,  0. ]])\n",
    "    >>> actual_item_similarity = get_item_similarity(test_user_item_ratings).round(1)\n",
    "    >>> np.array_equal(actual_item_similarity, expected_item_similarity)\n",
    "    True\n",
    "    \"\"\"\n",
    "    item_similarity = np.array([[]])\n",
    "    \n",
    "    # ADD YOUR CODE HERE\n",
    "    \n",
    "    return item_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b9dded",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d77cd7f3a8cc989ce6f75006440391c",
     "grade": true,
     "grade_id": "cell-47a83e02184cdb9a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test(get_item_similarity)\n",
    "    item_similarity = get_item_similarity(user_item_ratings[:, ::3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9125201e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51f9b7f5d69ae61ef966cd4910723044",
     "grade": false,
     "grade_id": "cell-85454a2382741463",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 3.2 Item-Item Recommendations\n",
    "\n",
    "Item-based recommendation is build on the notion that users will like something similar to what they liked in the past. Imagine for example a similarity matrix of three items A, B, and C:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "\t1 & 0.5 & 0  \\\\\n",
    "\t0.5 & 1 & 0.3  \\\\\n",
    "    0 & 0.3 & 1    \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In this artificial setting, items A and B have a similarity of 0.5 and item B and C of 0.3. Items A and C have no relation. If we'd know that a user liked item B and gave a rating of 10, item-based collaborative filtering would then assume through item similarity that our user would rate item A with a score of 5 and item C with 3.\n",
    "\n",
    "The k nearest neighbors in this model are the number of most similar items for each given item in the rating matrix that would be considered. E.g., in the example above, k=1 would mean that only item A is retrieved with its score of 5, since it is the most similar to item B.\n",
    "\n",
    "If we set k to all items in our dataset, we essentially compute the dot product between our user's rating vector and the item similarity matrix. For simplicity, let's implement that version of item-item recommendation below and ignore the parameter k.\n",
    "\n",
    "üìù Complete the method below and implement an item-item collaborative filtering recommendation. Retrieve the user's rating vector and rank items by the result of the dot product of that user vector with the item similarity matrix (no normalization applied for simplicity). Ignore again items that were already in the user's history and break ties in the resulting list by sorting by title. Round all resulting scores to 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf091b6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20a3c682ae30b28040222a6c18e7bbf9",
     "grade": false,
     "grade_id": "cell-0fbd4d223525d562",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_item_item_recommendations(\n",
    "    user_item_ratings: np.ndarray,\n",
    "    similarity_matrix: np.ndarray,\n",
    "    user_id: int,\n",
    "    n_results: int,\n",
    "    id2title: Dict[int, str]\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    >>> get_item_item_recommendations(user_item_ratings[:, ::3], item_similarity, user_id=971, n_results=3, id2title=id2title)\n",
    "    [('From the Dust Returned: A Novel', 12.6822), ('Junky', 12.5776), ('The Rival (Rival)', 11.7701)]\n",
    "    \n",
    "    >>> get_item_item_recommendations(user_item_ratings[:, ::3], item_similarity, user_id=653, n_results=3, id2title=id2title)\n",
    "    [('The Indictment', 0.9135), ('The Last Convertible', 0.4855), ('Crown Duel (Smith, Sherwood. Crown and Court Duet, Bk. 1-2.)', 0.36)]\n",
    "    \n",
    "    >>> get_item_item_recommendations(user_item_ratings[:, ::3], item_similarity, user_id=151, n_results=3, id2title=id2title)\n",
    "    [('Northanger Abbey (English Library)', 6.2228), ('A Secret Affair', 5.944), ('Soul Mates', 5.7874)]\n",
    "    \n",
    "    >>> get_item_item_recommendations(user_item_ratings[:, ::3], item_similarity, user_id=1141, n_results=5, id2title=id2title)\n",
    "    [('The Hours : A Novel', 5.956), ('The Bestseller', 5.7026), (\"When You Look Like Your Passport Photo, It's Time to Go Home\", 4.8398), (\"The French Lieutenant's Woman (French Lieutenant's Woman)\", 3.9785), (\"London's Perfect Scoundrel : Lessons in Love (Lessons in Love)\", 3.9451)]\n",
    "    \"\"\"\n",
    "    titles = []\n",
    "    \n",
    "    # ADD YOUR CODE HERE\n",
    "    \n",
    "    return titles[:n_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09546545",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a4b03e28bec74a66e55129dd5464258",
     "grade": true,
     "grade_id": "cell-331c9bec3837db31",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test(get_item_item_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d9b993",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9721843b3b899a16853736ad36aef91",
     "grade": false,
     "grade_id": "cell-51b2862b838ccb99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 3.3 Comparing Approaches\n",
    "\n",
    "To end this assignment, let's think about when we should use different recommendation paradigmns.\n",
    "\n",
    "‚ùìYour online shop for used Nintendo games is not taking off. So far you have 238 games in stock but last month only 18 users logged in and used your website. What is more memory efficient item-item or user-user recommendation? Does your answer change once you have 500 visitors a month?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb618c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc64987ac347b29a1e39d6b54e7f5de3",
     "grade": true,
     "grade_id": "cell-a477b6812821d48c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">ADD YOUR ANSWER HERE</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd139ee0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "932c45ccb95d97d2d37cfe57680f08e2",
     "grade": false,
     "grade_id": "cell-210d0e2a15ad6d7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "‚ùìPopularity bias is the tendency of recommender systems to overly recommend very popular items. Compare collaborative filtering with content-based recommendation, which is more prone to this bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3043af89",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a043fabf3d98d734d1e88c4e08dc29ea",
     "grade": true,
     "grade_id": "cell-87e873fc34372c8d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">ADD YOUR ANSWER HERE</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
